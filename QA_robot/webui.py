#!/usr/bin/env python
# -*- coding: UTF-8 -*-

'''
@Project ï¼šCheese_AI
@File ï¼šwebui.py
@Author ï¼šCheese
@Date ï¼š2023/6/13 18:16
'''
from langchain.document_loaders import UnstructuredWordDocumentLoader # ç²˜åˆå‰‚:å¸®åŠ©ç²˜åˆä¸‹é¢çš„éœ€è¦ç”¨åˆ°çš„å„ç§å·¥å…· # pip install langchain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings

import pinecone # å‘é‡æ•°æ®åº“ # pip install pinecone-client

import os
from env import OPENAI_API_KEY,PINECONE_API_KEY,PINECONE_API_ENV,INDEX_NAME


from langchain.vectorstores import Pinecone

import streamlit as st # å¿«é€Ÿåˆ›å»ºç½‘ç«™çš„å¼€æºå·¥å…· # pip install streamlit
import gtts # è°·æ­Œæ–‡å­—è½¬è¯­éŸ³ # pip install gtts
from langchain.llms import OpenAI # å¤§è¯­è¨€æ¨¡å‹å¸®åŠ©æˆ‘ä»¬åˆ†ææ–‡æ¡£ä»¥åŠå›ç­”é—®é¢˜

from langchain.chains.question_answering import load_qa_chain
import pinecone # å‘é‡æ•°æ®åº“ # pip install pinecone-client
from env import OPENAI_API_KEY,PINECONE_API_KEY,PINECONE_API_ENV,INDEX_NAME
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Pinecone
import os

import os
os.environ["http_proxy"]="127.0.0.1:4780" # ä½ ç”µè„‘ -> ç½‘ç»œå’ŒInternet -> ä»£ç† -> ä½¿ç”¨ä»£ç†æœåŠ¡å™¨å¤„ -> å–è‡ªè¿™é‡Œçš„ipå’Œport
os.environ["https_proxy"]="127.0.0.1:4780"
'''
å­˜å‚¨å®Œæˆå‘é‡æ•°æ®åº“ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥è¿è¡Œä¸‹é¢çš„ä»£ç ï¼Œç”¨streamlitå¸®æˆ‘ä»¬åšä¸€ä¸ªç®€å•çš„ç½‘é¡µå¯ä»¥ç”¨æ¥è°ƒç”¨æˆ‘ä»¬çš„æœºå™¨äººé—®ç­”
'''
# App framework
# å¦‚ä½•åˆ›å»ºè‡ªå·±çš„ç½‘é¡µæœºå™¨äºº
st.title('ğŸ˜¬äº¤è§„å°ç§˜ä¹¦ğŸ˜¬') #ç”¨streamlit appåˆ›å»ºä¸€ä¸ªæ ‡é¢˜
# åˆ›å»ºä¸€ä¸ªè¾“å…¥æ å¯ä»¥è®©ç”¨æˆ·å»è¾“å…¥é—®é¢˜
query = st.text_input('å—¨ï¼Œæˆ‘æ˜¯ä½ çš„ç§äººäº¤è§„å°ç§˜ä¹¦,ä½ å¯ä»¥é—®æˆ‘å…³äºäº¤é€šæ³•å¾‹çš„é—®é¢˜ï¼Œä¾‹å¦‚ï¼šä¸æŒ‰äº¤é€šä¿¡å·ç¯é€šè¡Œæ‰£å‡ åˆ†ï¼Ÿ')

my_bar = st.progress(0, text='ç­‰å¾…æŠ•å–‚é—®é¢˜å“¦') # ç¾åŒ–ï¼šåŠ è½½è¿›åº¦æ¡
# initialize search
# å¼€å§‹æœç´¢ï¼Œè§£ç­”
if query:
    pinecone.init(
        api_key=PINECONE_API_KEY,
        environment=PINECONE_API_ENV
    )
    #llmæ˜¯ç”¨æ¥å®šä¹‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œåœ¨ä¸‹é¢çš„ä¾‹å­ï¼Œç”¨çš„æ˜¯openaiï¼Œæ³¨æ„ï¼Œæ­¤openaiè°ƒç”¨çš„æ˜¯langchainæ–¹æ³•ä¸æ˜¯openaiæœ¬ai
    llm = OpenAI(temperature=0, max_tokens=-1, openai_api_key=OPENAI_API_KEY) # temperature=0ç»™æˆ‘éå¸¸ç¡®è®¤çš„ç­”æ¡ˆï¼Œä¸éœ€è¦åˆ›æ„
    print('1:'+ str(llm))
    my_bar.progress(10, text='æ­£åœ¨æŸ¥è¯¢æ–°åå­—å…¸')
    # embeddingå°±æ˜¯æŠŠæ–‡å­—å˜æˆæ•°å­—
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    print('2:'+ str(embeddings))
    # è°ƒç”¨pineconeçš„æ•°æ®åº“ï¼Œå¼€å§‹æŸ¥è¯¢ä»»åŠ¡
    docsearch = Pinecone.from_existing_index('cheese0',embedding=embeddings)
    print('3:'+ str(docsearch))
    # ç›¸ä¼¼åº¦æœç´¢ï¼Œä¾‹å¦‚ç–¼678ï¼Œç—›679ï¼Œæœç´¢ç”¨æˆ·çš„é—®é¢˜çš„ç›¸ä¼¼åº¦
    docs = docsearch.similarity_search(query, k=3) # åŒ¹é…åˆ°æœ€ç›¸å…³çš„æ˜¯kä¸ªæ–‡æ¡£ç»™æˆ‘ï¼Œæ¯ä¸ªæ–‡æ¡£ä¸Šè¾¹è®¾ç½®äº†æ˜¯500ä¸ªå­— # include_metadata=True # openaiåŸç†ï¼šembeddingå‘é‡åŒ–æˆ–semantic searchè¯­ä¹‰æœç´¢ã€‚é‡‡å–é«˜ä½ç›¸ä¼¼åº¦çš„è¿‘ä¼¼åº¦çš„æŸ¥è¯¢ã€‚å‡è®¾æ•°æ®é›†ä¸­æœ‰"æ‰£"åˆ†ï¼Œä½ é—®ä»–â€œå‡â€åˆ†ï¼Œè™½ç„¶æ•°æ®é›†ä¸­æ²¡æœ‰ï¼Œä½†æ˜¯æ‰£åœ¨å‘é‡åº“ä¸­æ˜¯788ï¼Œå‡åœ¨openaiä¸­æ˜¯789ï¼Œopenaiçš„æ¨¡å‹ä¸­å·²ç»é¢„è®¾äº†ï¼ŒçŸ¥é“ä»–ä»¬æ˜¯è¿‘ä¹‰è¯ã€‚
    print('4:'+ str(docs))
    my_bar.progress(60, text='æ‰¾åˆ°ç‚¹å¤´ç»ªäº†')
    # è°ƒç”¨langchainçš„load qaåŠæ³•ï¼Œâ€™stuffâ€˜ä¸ºä¸€ç§æ”¾å…¥openaiçš„åŠæ³•
    chain = load_qa_chain(llm, chain_type='stuff', verbose=True) # stuff ç¡¬å¡è¿›å»
    print('5:'+ str(chain))
    my_bar.progress(90, text='å¯ä»¥å¼€å§‹ç”Ÿæˆç­”æ¡ˆäº†ï¼Œè„‘ç»†èƒåœ¨ç‡ƒçƒ§')
    # å¾—åˆ°ç­”æ¡ˆ
    answer = chain.run(input_documents=docs, question=query, verbose=True)
    print('6:'+ str(answer))

    my_bar.progress(100, text='å¥½äº†') # ç¾åŒ–çš„ä¸œè¥¿
    st.write(answer)
    audio = gtts.gTTS(answer, lang='zh') # æ–‡å­—è½¬è¯­éŸ³
    audio.save("audio.wav")
    st.audio('audio.wav', start_time=0)
    os.remove("audio.wav")